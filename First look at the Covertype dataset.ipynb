{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowing the Covertype dataset\n",
    "\n",
    "## Description\n",
    "\n",
    "The Covertype dataset aims to provide cartographic variables (no remotely sensed data) for predicting forest cover types. Data is about four wilderness areas located in the Roosevelt National Forest of northern Colorado, whose cover types are more a result of ecological processes rather than human-caused disturbances.\n",
    "\n",
    "The original dataset contains 12 attributes (10 quantitative, 2 qualitative), but the collected data is organized in 54 columns, where 10 correspond to the quantitative variables, 4 are binary for encoding wilderness areas and 40 are also binary for encoding the soil type. A more detailed description is given in the table below:\n",
    "\n",
    "| Attribute name           | Type             | Measurement    | Description                          |\n",
    "| ------------------------ |:-----------------|:---------------|-------------------------------------:|\n",
    "| elevation                | quantitative     | meters         | Elevation in meters                  |\n",
    "| aspect                   | quantitative     | azimuth        | Aspect in degress azimuth            |\n",
    "| slope                    | quantitative     | degrees        | Slope in degress                     |\n",
    "| horiz_dist_hydro         | quantitative     | meters         | Horiz. Dist. to nearest surface water|    \n",
    "| vert_dist_hydro          | quantitative     | meters         | Vert. Dist. to nearest surface water |    \n",
    "| horiz_dist_road          | quantitative     | meters         | Horiz. Dist. to nearest roadway      |    \n",
    "| hillshade_9              | quantitative     | 0 to 255 index | Hillshade index at 9am, summer solstice|\n",
    "| hillshade_noon              | quantitative     | 0 to 255 index | Hillshade index at noon, summer solstice|\n",
    "| hillshade_15              | quantitative     | 0 to 255 index | Hillshade index at 3pm, summer solstice|\n",
    "| horiz_dist_fire          | quantitative     | meters         | Horiz. Dist. to nearest wildfire ignition points |    \n",
    "| wild_area[0-4]           | qualitative (4 classes)     | binary         | Wilderness area designation          |\n",
    "| soil_type[0-39]          | qualitative (40 classes)     | binary         | Soil type designation                |\n",
    "| cover_type               | integer          | 1 to 7         | Forest cover type designation        |\n",
    "\n",
    "The classification problem consists in classifying the forest cover into seven types:\n",
    "\n",
    "| Number | Type |           |\n",
    "| -------|------|-----------|\n",
    "| 1      | Spruce/Fir|<img src=\"imgs/spruce.jpg\" width=\"150px\" height=\"150px\"/>|\n",
    "| 2      | Lodgepole Pine|<img src=\"imgs/lodge.jpg\" width=\"150px\" height=\"150px\"/>|\n",
    "| 3      | Ponderosa Pine|<img src=\"imgs/ponderosa.jpg\" width=\"150px\" height=\"150px\"/>|\n",
    "| 4      | Cottonwood/Willow|<img src=\"imgs/cottonwood.jpg\" width=\"150px\" height=\"150px\"/>|\n",
    "| 5      | Aspen|<img src=\"imgs/aspen.jpg\" width=\"150px\" height=\"150px\"/>|\n",
    "| 6      | Douglas-fir|<img src=\"imgs/douglas.jpg\" width=\"150px\" height=\"150px\"/>|\n",
    "| 7      | Krummholz|<img src=\"imgs/krumm.jpg\" width=\"150px\" height=\"150px\"/>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and improving columns description\n",
    "\n",
    "Below is the code for loading and previewing the raw dataset using the `pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4     5    6    7    8     9  ...  45  46  47  48  49  \\\n",
       "0  2596   51   3  258    0   510  221  232  148  6279 ...   0   0   0   0   0   \n",
       "1  2590   56   2  212   -6   390  220  235  151  6225 ...   0   0   0   0   0   \n",
       "2  2804  139   9  268   65  3180  234  238  135  6121 ...   0   0   0   0   0   \n",
       "3  2785  155  18  242  118  3090  238  238  122  6211 ...   0   0   0   0   0   \n",
       "4  2595   45   2  153   -1   391  220  234  150  6172 ...   0   0   0   0   0   \n",
       "\n",
       "   50  51  52  53  54  \n",
       "0   0   0   0   0   5  \n",
       "1   0   0   0   0   5  \n",
       "2   0   0   0   0   2  \n",
       "3   0   0   0   0   2  \n",
       "4   0   0   0   0   5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read data as csv\n",
    "dataset = pd.read_csv(\"datasets/covtype.data\", header=None)\n",
    "# preview the five first lines\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the header doesn't exist in the original dataset, so the column indexing must be done only with integers. It is possible to improve this by changing the column indices to a more readable form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>horiz_dist_hydro</th>\n",
       "      <th>vert_dist_hydro</th>\n",
       "      <th>horiz_dist_road</th>\n",
       "      <th>hillshade_9</th>\n",
       "      <th>hill_shade_noon</th>\n",
       "      <th>hill_shade_15</th>\n",
       "      <th>horiz_dist_fire</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_type_31</th>\n",
       "      <th>soil_type_32</th>\n",
       "      <th>soil_type_33</th>\n",
       "      <th>soil_type_34</th>\n",
       "      <th>soil_type_35</th>\n",
       "      <th>soil_type_36</th>\n",
       "      <th>soil_type_37</th>\n",
       "      <th>soil_type_38</th>\n",
       "      <th>soil_type_39</th>\n",
       "      <th>cover_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation  aspect  slope  horiz_dist_hydro  vert_dist_hydro  \\\n",
       "0       2596      51      3               258                0   \n",
       "1       2590      56      2               212               -6   \n",
       "2       2804     139      9               268               65   \n",
       "3       2785     155     18               242              118   \n",
       "4       2595      45      2               153               -1   \n",
       "\n",
       "   horiz_dist_road  hillshade_9  hill_shade_noon  hill_shade_15  \\\n",
       "0              510          221              232            148   \n",
       "1              390          220              235            151   \n",
       "2             3180          234              238            135   \n",
       "3             3090          238              238            122   \n",
       "4              391          220              234            150   \n",
       "\n",
       "   horiz_dist_fire     ...      soil_type_31  soil_type_32  soil_type_33  \\\n",
       "0             6279     ...                 0             0             0   \n",
       "1             6225     ...                 0             0             0   \n",
       "2             6121     ...                 0             0             0   \n",
       "3             6211     ...                 0             0             0   \n",
       "4             6172     ...                 0             0             0   \n",
       "\n",
       "   soil_type_34  soil_type_35  soil_type_36  soil_type_37  soil_type_38  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   soil_type_39  cover_type  \n",
       "0             0           5  \n",
       "1             0           5  \n",
       "2             0           2  \n",
       "3             0           2  \n",
       "4             0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of column names\n",
    "column_names = [\"elevation\", \"aspect\", \"slope\", \\\n",
    "                \"horiz_dist_hydro\", \"vert_dist_hydro\", \\\n",
    "                \"horiz_dist_road\", \"hillshade_9\", \\\n",
    "                \"hill_shade_noon\", \"hill_shade_15\", \"horiz_dist_fire\"] \\\n",
    "                + [\"wild_area_\" + str(i) for i in range(0,4)] \\\n",
    "                + [\"soil_type_\" + str(i) for i in range(0,40)] \\\n",
    "                + [\"cover_type\"]\n",
    "# change column names in dataframe\n",
    "dataset.columns = column_names\n",
    "# confirm the dataset size\n",
    "print(\"Dataset shape: \" + str(dataset.shape))\n",
    "# check the resulting dataset with column names\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with class imbalancing\n",
    "\n",
    "This is the distribution of rows per classes:\n",
    "\n",
    "| Type | Number of rows |\n",
    "| -----|----------------|\n",
    "| Spruce/Fir | 211840|\n",
    "| Lodgepole Pine| 283301|\n",
    "| Ponderosa Pine | 35754|\n",
    "| Corronwood/Willow| 2747|\n",
    "| Aspen | 9493|\n",
    "| Douglas-fir | 17367|\n",
    "| Krummholz | 20510|\n",
    "| **Total** | **581012**|\n",
    "\n",
    "One can notice that this is a very unbalanced dataset, since there is a huge difference between the amount of individuals between classes. Since this dataset has a lot of instances and the minimum of the number of instances in a class seems still to be substantial, the dataset will be reduced in a way that every class will have 2747 instances. In this work, random 2747 instances in each class will be selected, and the rest will be kept in another dataset. The code below does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorgreati/miniconda3/envs/ia/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape:(19229, 55)\n",
      "Remaining dataset shape:(563676, 55)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# group by cover type\n",
    "groups = dataset.groupby(\"cover_type\")\n",
    "# get minimum number of instances in a class\n",
    "number_samples = groups.size().min()\n",
    "# produce the new dataset\n",
    "new_dataset = pd.concat([resample(df, replace=True, \\\n",
    "                                  n_samples=number_samples, \\\n",
    "                                  random_state=123) for _, df in groups])\n",
    "# keeps the remaining dataset\n",
    "remaining_dataset = pd.concat([dataset, new_dataset]).drop_duplicates(keep=False)\n",
    "# check sizes\n",
    "print(\"New dataset shape:\" + str(new_dataset.shape))\n",
    "print(\"Remaining dataset shape:\" + str(remaining_dataset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values analysis\n",
    "\n",
    "There are no missing values in this dataset. In order to check this fact, it is possible to use the `missingno` library to generate a simple visualization of the new dataset (the dataset of remaining instances would behave the same), where the color white means missing values in a column (notice how everything is dark for this dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fac1bc4df98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "# improve plotting visualization\n",
    "%matplotlib inline\n",
    "# plot a graph showing the missing values (in this case, there are none)\n",
    "msno.matrix(new_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate features and targets\n",
    "\n",
    "For further manipulations, lets separate targets from features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target size: (19229,)\n",
      "Data size: (19229, 54)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve targets\n",
    "targets = new_dataset['cover_type']\n",
    "# Retrieve features\n",
    "features_data = new_dataset.drop('cover_type', axis=1, inplace=False)\n",
    "# Check shapes\n",
    "print(\"Target size: \" + str(targets.shape))\n",
    "print(\"Data size: \" + str(features_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test separation\n",
    "\n",
    "In several Machine Learning methods, it is important to split the dataset into test and train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (14421, 54)\n",
      "Train targets: (14421,)\n",
      "Test features: (4808, 54)\n",
      "Test targets: (4808,)\n",
      "\n",
      "[INFO] Train features sample\n",
      "        elevation  aspect  slope  horiz_dist_hydro  vert_dist_hydro  \\\n",
      "246630       1936     320     26                30               21   \n",
      "362439       3439     338     15               582               80   \n",
      "523123       3338      86     25               190               45   \n",
      "25512        2574     341     14                 0                0   \n",
      "137946       2928     346      6               162               20   \n",
      "\n",
      "        horiz_dist_road  hillshade_9  hill_shade_noon  hill_shade_15  \\\n",
      "246630               85          143              204            196   \n",
      "362439             1921          186              217            170   \n",
      "523123             2172          247              189             57   \n",
      "25512              1332          191              219            167   \n",
      "137946             5055          209              231            160   \n",
      "\n",
      "        horiz_dist_fire      ...       soil_type_30  soil_type_31  \\\n",
      "246630              484      ...                  0             0   \n",
      "362439              469      ...                  0             0   \n",
      "523123             2044      ...                  0             0   \n",
      "25512              5044      ...                  0             0   \n",
      "137946             1705      ...                  0             0   \n",
      "\n",
      "        soil_type_32  soil_type_33  soil_type_34  soil_type_35  soil_type_36  \\\n",
      "246630             0             0             0             0             0   \n",
      "362439             0             0             0             0             0   \n",
      "523123             0             0             0             0             0   \n",
      "25512              0             0             0             0             0   \n",
      "137946             0             0             0             0             0   \n",
      "\n",
      "        soil_type_37  soil_type_38  soil_type_39  \n",
      "246630             0             0             0  \n",
      "362439             0             1             0  \n",
      "523123             0             1             0  \n",
      "25512              0             0             0  \n",
      "137946             0             0             0  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "\n",
      "[INFO] Train targets sample\n",
      "246630    3\n",
      "362439    7\n",
      "523123    7\n",
      "25512     2\n",
      "137946    5\n",
      "Name: cover_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into train and test sets\n",
    "train_features, test_features, train_targets, test_targets  = train_test_split(\n",
    "    features_data, \n",
    "    targets,\n",
    "    test_size=0.25,\n",
    "    train_size=0.75,\n",
    "    random_state=42)\n",
    "# Check shapes\n",
    "print(\"Train features: \" + str(train_features.shape))\n",
    "print(\"Train targets: \" + str(train_targets.shape))\n",
    "print(\"Test features: \" + str(test_features.shape))\n",
    "print(\"Test targets: \" + str(test_targets.shape))\n",
    "# Check head\n",
    "print(\"\\n[INFO] Train features sample\")\n",
    "print(train_features.head())\n",
    "print(\"\\n[INFO] Train targets sample\")\n",
    "print(train_targets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization\n",
    "\n",
    "Also, in order to avoid future problems with data magnitude, normalization is applied in the train set.\n",
    "Here, the `StandardScaler` class is responsible for that, whose effect is to remove the mean and scale\n",
    "to unit variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Train features sample\n",
      "        elevation    aspect     slope  horiz_dist_hydro  vert_dist_hydro  \\\n",
      "246630  -1.929805  1.477831  1.116461         -0.948019        -0.487945   \n",
      "362439   1.644997  1.640937 -0.184168          1.692577         0.475531   \n",
      "523123   1.404774 -0.642539  0.998222         -0.182629        -0.096023   \n",
      "25512   -0.412357  1.668121 -0.302407         -1.091529        -0.830878   \n",
      "137946   0.429612  1.713428 -1.248319         -0.316572        -0.504275   \n",
      "\n",
      "        horiz_dist_road  hillshade_9  hill_shade_noon  hill_shade_15  \\\n",
      "246630        -1.219708    -2.282350        -0.643397       1.322887   \n",
      "362439         0.161461    -0.874140        -0.075690       0.761317   \n",
      "523123         0.350281     1.123554        -1.298443      -1.679356   \n",
      "25512         -0.281626    -0.710395         0.011650       0.696520   \n",
      "137946         2.519079    -0.120911         0.535686       0.545328   \n",
      "\n",
      "        horiz_dist_fire      ...       soil_type_30  soil_type_31  \\\n",
      "246630        -0.934126      ...          -0.141736     -0.214972   \n",
      "362439        -0.947689      ...          -0.141736     -0.214972   \n",
      "523123         0.476446      ...          -0.141736     -0.214972   \n",
      "25512          3.189085      ...          -0.141736     -0.214972   \n",
      "137946         0.169918      ...          -0.141736     -0.214972   \n",
      "\n",
      "        soil_type_32  soil_type_33  soil_type_34  soil_type_35  soil_type_36  \\\n",
      "246630     -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "362439     -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "523123     -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "25512      -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "137946     -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "\n",
      "        soil_type_37  soil_type_38  soil_type_39  \n",
      "246630     -0.224338     -0.218305     -0.174891  \n",
      "362439     -0.224338      4.580746     -0.174891  \n",
      "523123     -0.224338      4.580746     -0.174891  \n",
      "25512      -0.224338     -0.218305     -0.174891  \n",
      "137946     -0.224338     -0.218305     -0.174891  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "\n",
      "[INFO] Train targets sample\n",
      "246630    3\n",
      "362439    7\n",
      "523123    7\n",
      "25512     2\n",
      "137946    5\n",
      "Name: cover_type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorgreati/miniconda3/envs/ia/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Keep columns index to use later\n",
    "(feature_columns, feature_index) = (train_features.columns, train_features.index)\n",
    "# Retrieve only the values\n",
    "features_data_values = train_features.values\n",
    "# Build the normalizer\n",
    "scaler = StandardScaler().fit(features_data_values)\n",
    "# Standardize data\n",
    "features_data_values = scaler.transform(features_data_values)\n",
    "# Back features to DataFrame\n",
    "train_features = pd.DataFrame(features_data_values, columns=feature_columns, index=feature_index)\n",
    "# Check first row\n",
    "# Check head\n",
    "print(\"\\n[INFO] Train features sample\")\n",
    "print(train_features.head())\n",
    "print(\"\\n[INFO] Train targets sample\")\n",
    "print(train_targets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping scaler\n",
    "\n",
    "It is important to save the scaler since it is a model for normalizing the data based on the\n",
    "train set and may be used for transforming future data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scaler.save']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "# Save the scaler in the models/ folder\n",
    "joblib.dump(scaler, 'models/scaler.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the test set\n",
    "\n",
    "Now, apply the normalization in the test set. Let's simulate the loading process of the scaler, like in a real situation of confronting new data samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Train features sample\n",
      "        elevation    aspect     slope  horiz_dist_hydro  vert_dist_hydro  \\\n",
      "43354    0.572319 -0.932504 -0.420646          1.175939         0.295900   \n",
      "11345   -0.336247 -0.497556 -1.011841         -0.077388        -0.749227   \n",
      "260737   1.212120 -1.240592 -1.248319          0.190499        -0.340974   \n",
      "574033  -0.079375  0.671366 -0.893602          0.066123         0.932774   \n",
      "366456   1.235905 -1.122794  0.288788          0.343577         0.834793   \n",
      "\n",
      "        horiz_dist_road  hillshade_9  hill_shade_noon  hill_shade_15  \\\n",
      "43354          2.560454     0.468572        -0.337708      -0.426622   \n",
      "11345         -0.823261     0.697816         0.492017      -0.145836   \n",
      "260737         1.983462     0.108332         0.404677       0.307740   \n",
      "574033         0.676015    -0.251907         1.321742       0.977305   \n",
      "366456         1.313941     0.010085        -1.080094      -0.534616   \n",
      "\n",
      "        horiz_dist_fire      ...       soil_type_30  soil_type_31  \\\n",
      "43354          3.724379      ...          -0.141736     -0.214972   \n",
      "11345          4.224409      ...          -0.141736     -0.214972   \n",
      "260737         0.754944      ...          -0.141736     -0.214972   \n",
      "574033        -0.312027      ...          -0.141736     -0.214972   \n",
      "366456         0.541550      ...           7.055365     -0.214972   \n",
      "\n",
      "        soil_type_32  soil_type_33  soil_type_34  soil_type_35  soil_type_36  \\\n",
      "43354      -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "11345      -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "260737     -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "574033     -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "366456     -0.205073      -0.04331     -0.079247     -0.014425     -0.041672   \n",
      "\n",
      "        soil_type_37  soil_type_38  soil_type_39  \n",
      "43354      -0.224338     -0.218305     -0.174891  \n",
      "11345      -0.224338     -0.218305     -0.174891  \n",
      "260737      4.457550     -0.218305     -0.174891  \n",
      "574033     -0.224338     -0.218305     -0.174891  \n",
      "366456     -0.224338     -0.218305     -0.174891  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "\n",
      "[INFO] Train targets sample\n",
      "43354     1\n",
      "11345     5\n",
      "260737    7\n",
      "574033    3\n",
      "366456    7\n",
      "Name: cover_type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorgreati/miniconda3/envs/ia/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the scaler\n",
    "scaler = joblib.load('models/scaler.save')\n",
    "# Keep columns index to use later\n",
    "(feature_columns, feature_index) = (test_features.columns, test_features.index)\n",
    "# Apply normalization in test set\n",
    "test_features_values = scaler.transform(test_features.values)\n",
    "# Back to DataFrame\n",
    "test_features = pd.DataFrame(test_features_values, columns=feature_columns, index=feature_index)\n",
    "# Check first row\n",
    "test_features.head()\n",
    "# Check head\n",
    "print(\"\\n[INFO] Train features sample\")\n",
    "print(test_features.head())\n",
    "print(\"\\n[INFO] Train targets sample\")\n",
    "print(test_targets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new datasets\n",
    "\n",
    "After generating the train and test datasets, and the dataset with the remaining values, their csv versions need to be stored, in order to use them in the next steps of this work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (14421, 55)\n",
      "Test shape: (4808, 55)\n",
      "[INFO] Saving train...\n",
      "[INFO] Saving test...\n",
      "[INFO] Done.\n"
     ]
    }
   ],
   "source": [
    "# Join features and targets\n",
    "train_set = pd.concat([train_features, train_targets], axis=1)\n",
    "test_set = pd.concat([test_features, test_targets], axis=1)\n",
    "# Check shapes\n",
    "print(\"Train shape: \" + str(train_set.shape))\n",
    "print(\"Test shape: \" + str(test_set.shape))\n",
    "# Save datasets\n",
    "print(\"[INFO] Saving train...\")\n",
    "train_set.to_csv(\"datasets/covertype_norm_train.csv\", index=False)\n",
    "print(\"[INFO] Saving test...\")\n",
    "test_set.to_csv(\"datasets/covertype_norm_test.csv\", index=False)\n",
    "print(\"[INFO] Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, save the remaining data from the dataset for future usage (check if this file already exists, otherwise it is not necessary to run the next cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Saving remaining...\")\n",
    "remaining_dataset.to_csv(\"datasets/covertype_remaining.csv\", index=False)\n",
    "print(\"[INFO] Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
