{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction: summary and analysis\n",
    "\n",
    "\n",
    "The table below summarizes the results of the k-NN executions according to each dimensionality reduction\n",
    "strategy applied up to now in this work:\n",
    "\n",
    "\n",
    "| Method                      | Parameters                                                                                           | Number of attributes | k-NN accuracy, k=1 (%) | Decision Tree Accuracy (%)\n",
    "|----------------------------------------|-------------------------------------------------------------------------------------------------------------------|----------------------|-------------------|----------------|\n",
    "| None  (Original data)                      | -                                                                                                    | 54                   | 83.31             | 81.26|\n",
    "| Particle Swarm Optimization | Swarm size = 100;<br/> Max iterations = 100                                                                  | 7                   | 30.36             | 33.42 |\n",
    "| Genetic Algorithm           |  Population size = 25;<br/>Max generations = 100;<br/>Combination probability = 0.7;<br/> Mutation probability = 0.1 | 1                   | 18.55             | 18.55|\n",
    "| PCA | 0.95| 40|79.30|76.22|\n",
    "| LDA | n_components=6|6|83.94|76.91|\n",
    "| Correlation filter | 60%| 32 (60%)|81.57|78.34|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections presents some discussion about the results above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poor results for PSO and GA related to the quality of the fitness function\n",
    "\n",
    "Results for PSO and GA in the table above were selected among the various (30, to be precise) executions of the algorithms\n",
    "based on the fitness function: the solutions with best fitness were selected. Results, as one can see\n",
    "in the table, were poor. If the fitness function was really suitable for those algorithms, no other\n",
    "solution would perform better, since correlation with respect to the target is a good measure,\n",
    "what can be observed by the Correlation filter results. \n",
    "\n",
    "That, however, was not the case: there were\n",
    "solutions that perfomed much better in the classification task considering k-NN (with k=1) and Decision Tree classifiers. To\n",
    "notice that, classification was executed for all solutions and the ones with best accuracy results were\n",
    " selected. Such results, in fact, were far better:\n",
    "\n",
    "\n",
    "| Method                      | Parameters                                                                                           | Number of attributes | k-NN accuracy, k=1 (%) \n",
    "|----------------------------------------|-------------------------------------------------------------------------------------------------------------------|----------------------|-------------------|\n",
    "| Particle Swarm Optimization | Swarm size = 25;<br/> Max iterations = 100                                                                  | 22                   | 85.48             | \n",
    "| Genetic Algorithm           |  Population size = 25;<br/>Max generations = 50;<br/>Combination probability = 0.9;<br/> Mutation probability = 0.05 | 17                   | 77.28             |\n",
    "\n",
    "| Method                      | Parameters                                                                                           | Number of attributes |  Decision Tree Accuracy (%)\n",
    "|----------------------------------------|-------------------------------------------------------------------------------------------------------------------|----------------------|----------------|\n",
    "| Particle Swarm Optimization | Swarm size = 100;<br/> Max iterations = 200                                                                  | 21                   |  80.53 |\n",
    "| Genetic Algorithm           |  Population size = 25;<br/>Max generations = 50;<br/>Combination probability = 0.9;<br/> Mutation probability = 0.05 | 24                   |  75.22|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasons for the significant results of Correlation filter\n",
    "\n",
    "One could ask: if the fitness function for PSO and GA was based on correlation and didn't perform well,\n",
    "why did Correlation filter method provide good results? A possible interpertation is that the fitness function\n",
    "uses the mean of correlations of the selected attributes, a measure that is affected by outliers. Also, the mechanics of the optimization process performed by PSO and GA is prone to select few attributes with high accuracy, discarding others that may be important for the classification task. The simple filter, in turn, is direct: it certainly takes the attributes with higher correlations. \n",
    "\n",
    "Also, Spierman correlation was used in this filter, and the better performance could be explained by a nonlinear relation of the variables captured by this method that could not be perceived by Pearson's correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasons for better performance of k-NN over Decision Tree\n",
    "\n",
    "Results showed that the k-NN classifier performed better than the Decision Tree model. Also, a neighborhood size of 1 ($k=1$) was enough to provide the best results in the majority of the executions. A possible explanation for those behaviours is the possible high class intersection: $k$ values greater than $1$ lower the accuracy, so there may exist instances of other classes very near to the instance being classified. Also, such intersection difficults the space partition (decision surface) performed implicitly by the Decision Tree model, which could lower its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA: the best cost-benefit\n",
    "\n",
    "Tables above show that PSO achieved the higher accuracies considering the k-NN classifier, suplanting the original dataset, and the Decision Tree, almost reaching the accuracy of the original dataset. However, the best cost-benefit should be accredited to LDA: it presented almost the same accuracy with respect to PSO, but extracted only 6 attributes! It means that the dataset was reduced from 54 columns to only 6, a reduction of almost $89\\%$.\n",
    "Reasons for such success come from the nature of the LDA mechanics: it uses the targets to minimize the inner class scatter and to maximize the between class scatter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree: Analysis of trees' structure\n",
    "\n",
    "The table below summarizes the number of nodes and leaves, and also the heights of the trees' models, which were obtained on executions of the decision tree algorithm.\n",
    "\n",
    "| Method                      | Parameters                                                                                           | Number of nodes | Number of leaves | Height\n",
    "|----------------------------------------|-------------------------------------------------------------------------------------------------------------------|----------------------|-------------------|----------------|\n",
    "| None  (Original data)                      | -                                                                                                    | 3855                   | 1928             | 58|\n",
    "| Particle Swarm Optimization (Selected) | Swarm size = 100;<br/> Max iterations = 100                                                                  | 23                   | 12             | 8 |\n",
    "| Particle Swarm Optimization (Best) | Swarm size = 100;<br/> Max iterations = 200                                                                  | 4477                   | 2239             | 29 |\n",
    "| Genetic Algorithm (Selected)          |  Population size = 25;<br/>Max generations = 100;<br/>Combination probability = 0.7;<br/> Mutation probability = 0.1 | 3                   | 2             | 2|\n",
    "| Genetic Algorithm (Best)          |  Population size = 25;<br/>Max generations = 50;<br/>Combination probability = 0.9;<br/> Mutation probability = 0.05 | 5809                   | 2905             | 28|\n",
    "| PCA | 0.95| 3979|1990|31|\n",
    "| LDA | n_components=6|4593|2297|27|\n",
    "| Correlation filter | 60%| 4895|2448|37|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to notice is that the selected methods with `PSO` and `GA` have too short trees, which leads one to believe that the low accuracy obtained with these methods was caused by an underfitting. The remaining methods have very close attributes, and this shows how close the accuracies are.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
