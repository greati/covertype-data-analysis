{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-means clustering\n",
    "\n",
    "$k$-means clustering aims to partition the instances space into $k$ clusters, in which each observation\n",
    "belongs to the cluster with the nearest mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets\n",
    "\n",
    "Here, train and test datasets will be used together. Also, since this is an unsupervised technique, \n",
    "the target column will be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# dataset paths\n",
    "paths = ['../datasets/covertype_norm_train.csv',\n",
    "         '../datasets/covertype_norm_test.csv']\n",
    "# load train and test datasets together\n",
    "dataset = pd.concat([pd.read_csv(f) for f in paths])\n",
    "# keep targets for future comparative purposes\n",
    "targets = dataset['cover_type']\n",
    "# remove target column\n",
    "dataset.drop('cover_type', inplace=True, axis=1)\n",
    "# check shape\n",
    "print(\"[INFO] Dataset shape: \", dataset.shape)\n",
    "# check head\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "#### Varying $k$\n",
    "\n",
    "$k$ is the number of clusters to be constructed during the execution. It is important to vary it in order to \n",
    "seek for better partitions. In this work, $k \\in \\{2,3, \\ldots, 13\\}$. Notice that the number of classes\n",
    "is in the middle of this interval.\n",
    "\n",
    "#### Number of executions\n",
    "\n",
    "For each value of $k$, $5$ executions will be performed.\n",
    "\n",
    "#### Davies-Bouldin (DB) index\n",
    "\n",
    "Every clustering will then be evaluated in the view of the Davies-Bouldin (DB) index:\n",
    "\n",
    "$$\n",
    "R_{ij} = \\frac{s_i + s_j}{d_{ij}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "D_i = \\max_{j\\neq i}R_{ij}\n",
    "$$\n",
    "\n",
    "$$\n",
    "DB = \\frac 1 k \\sum_i D_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing $k$-means\n",
    "\n",
    "Here, the `sklearn` library will be used for performing the executions described in the methodology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "# k values\n",
    "#ks = list(range(2,14))\n",
    "ks = list(range(2,5))\n",
    "# number of executions per k\n",
    "ns = list(range(2))\n",
    "# store execution results\n",
    "results_execs = []\n",
    "# store models\n",
    "models = {}\n",
    "# iterate over ns\n",
    "for n in ns:\n",
    "    # seed\n",
    "    ms = round(((time.time()*1000.0) - 0)/(2**32-1 - 0))\n",
    "    # for each k\n",
    "    for k in ks:\n",
    "        print(\"[INFO] k =\", k, \", n =\", n)\n",
    "        # perform k-means\n",
    "        kmeans = KMeans(n_clusters=k, \n",
    "                        random_state=ms).fit(dataset)\n",
    "        # store model\n",
    "        models[(k, n)] = kmeans\n",
    "        # retrieve labels\n",
    "        labels = kmeans.labels_\n",
    "        # compute DB index\n",
    "        db = davies_bouldin_score(dataset, labels)\n",
    "        # info\n",
    "        print(\"seed\", ms, \", db = \", db)\n",
    "        # store results\n",
    "        results_execs.append([k, n, ms, db])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the average DB per $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe from results\n",
    "results_execs = pd.DataFrame(results_execs, \n",
    "                             columns=['k', 'iteration', \n",
    "                                      'random_seed','db_index'])\n",
    "# take average\n",
    "results_execs_avg = results_execs.groupby('k', axis=0).mean()['db_index']\n",
    "# get the k with min db average\n",
    "best_k = results_execs_avg.idxmin()\n",
    "# take the partition id with best_k clusters and min db\n",
    "best_partition_idx = results_execs[results_execs['k']==best_k]['db_index'].idxmin()\n",
    "# take the partition\n",
    "best_partition = results_execs.iloc[best_partition_idx]\n",
    "print(\"[INFO] Best partition:\")\n",
    "best_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the best  partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# recover the model\n",
    "model = models[(int(best_partition['k']), \n",
    "                int(best_partition['iteration']))]\n",
    "# dump it\n",
    "joblib.dump(model, '../models/best_kmeans.save') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_execs.to_csv('../results/kmeans_exec_results.csv',\n",
    "                     index=False)\n",
    "results_execs_avg.to_csv('../results/kmeans_avg_db.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
