{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayesian classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset(paths):\n",
    "    '''\n",
    "    Load the datasets in paths, return the data and the targets.\n",
    "    '''\n",
    "    # load train and test datasets together\n",
    "    dataset = pd.concat([pd.read_csv(f) for f in paths])\n",
    "    # keep targets for future comparative purposes\n",
    "    targets = dataset['cover_type']\n",
    "    # remove target column\n",
    "    dataset.drop('cover_type', inplace=True, axis=1)\n",
    "    # check shape\n",
    "    print(\"[INFO] Dataset shape: \", dataset.shape)\n",
    "    # return\n",
    "    return (dataset, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to perform the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def prepare_naive_model(X, y, path_save_model):\n",
    "    '''\n",
    "    Perform naive bayes classification.\n",
    "    '''\n",
    "    # train model\n",
    "    model = GaussianNB()\n",
    "    print(\"[INFO] Fitting...\")\n",
    "    model.fit(X, y)\n",
    "    # save it\n",
    "    print(\"[INFO] Saving...\")\n",
    "    joblib.dump(model,path_save_model)\n",
    "    # return it\n",
    "    print(\"[INFO] Done.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to perform normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def normality_test(dataset):\n",
    "    '''\n",
    "    Performs three normality tests on the data:\n",
    "    Shapiro-Wilker and D'Agostino.\n",
    "    '''\n",
    "    shapiro = [p for (_,p) in map(stats.shapiro, [dataset[c] for c in dataset.columns])]\n",
    "    _, dagostino = stats.normaltest(dataset)\n",
    "    return {'shapiro':shapiro, 'dagostino':dagostino}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset shape:  (14421, 54)\n",
      "[INFO] Dataset shape:  (4808, 54)\n",
      "[INFO] Dataset shape:  (14421, 6)\n",
      "[INFO] Dataset shape:  (4808, 6)\n"
     ]
    }
   ],
   "source": [
    "original_train_dataset, original_train_targets = load_dataset(['../datasets/covertype_norm_train.csv'])\n",
    "original_test_dataset, original_test_targets = load_dataset(['../datasets/covertype_norm_test.csv'])\n",
    "lda_train_dataset, lda_train_targets = load_dataset(['../datasets/covertype_lda_train.csv'])\n",
    "lda_test_dataset, lda_test_targets = load_dataset(['../datasets/covertype_lda_test.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normality tests for original: \n",
      " {'shapiro': [0.0, 0.0, 2.802596928649634e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 5.083340120300435e-30, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'dagostino': array([0.00000000e+000, 0.00000000e+000, 2.76074249e-136, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       1.62863745e-061, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       5.09771520e-061, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       6.06404803e-001, 6.06404803e-001, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       6.06404803e-001, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000])}\n",
      "[INFO] Normality tests for LDA: \n",
      " {'shapiro': [0.0, 0.0, 3.835278953208948e-32, 1.1201098507078527e-38, 0.0, 0.0], 'dagostino': array([0.00000000e+00, 0.00000000e+00, 7.16313520e-01, 9.96070832e-88,\n",
      "       0.00000000e+00, 0.00000000e+00])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorgreati/miniconda3/envs/ia/lib/python3.7/site-packages/scipy/stats/morestats.py:1309: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n",
      "/home/vitorgreati/miniconda3/envs/ia/lib/python3.7/site-packages/scipy/stats/morestats.py:1306: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    }
   ],
   "source": [
    "normality_original = normality_test(original_train_dataset)\n",
    "normality_lda = normality_test(lda_train_dataset)\n",
    "print(\"[INFO] Normality tests for original: \\n\", normality_original)\n",
    "print(\"[INFO] Normality tests for LDA: \\n\", normality_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fitting...\n",
      "[INFO] Saving...\n",
      "[INFO] Done.\n",
      "[INFO] Fitting...\n",
      "[INFO] Saving...\n",
      "[INFO] Done.\n"
     ]
    }
   ],
   "source": [
    "# train with original\n",
    "original_model = prepare_naive_model(original_train_dataset, original_train_targets, '../models/naive_original.save')\n",
    "# train with original\n",
    "lda_model = prepare_naive_model(lda_train_dataset, lda_train_targets, '../models/naive_lda.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "We're going to use the accuracy score with respect to the test set in order to evaluate the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Original acc score: 0.4317803660565724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "original_preds = original_model.predict(original_test_dataset)\n",
    "original_acc_score = accuracy_score(original_test_targets, original_preds)\n",
    "print(\"[INFO] Original acc score:\", original_acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] LDA acc score: 0.6356073211314476\n"
     ]
    }
   ],
   "source": [
    "lda_preds = lda_model.predict(lda_test_dataset)\n",
    "lda_acc_score = accuracy_score(lda_test_targets, lda_preds)\n",
    "print(\"[INFO] LDA acc score:\", lda_acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
