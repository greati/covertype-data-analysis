{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayesian classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset(paths):\n",
    "    '''\n",
    "    Load the datasets in paths, return the data and the targets.\n",
    "    '''\n",
    "    # load train and test datasets together\n",
    "    dataset = pd.concat([pd.read_csv(f) for f in paths])\n",
    "    # keep targets for future comparative purposes\n",
    "    targets = dataset['cover_type']\n",
    "    # remove target column\n",
    "    dataset.drop('cover_type', inplace=True, axis=1)\n",
    "    # check shape\n",
    "    print(\"[INFO] Dataset shape: \", dataset.shape)\n",
    "    # return\n",
    "    return (dataset, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to perform the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def prepare_naive_model(X, y, path_save_model):\n",
    "    '''\n",
    "    Perform naive bayes classification.\n",
    "    '''\n",
    "    # train model\n",
    "    model = GaussianNB()\n",
    "    print(\"[INFO] Fitting...\")\n",
    "    model.fit(X, y)\n",
    "    # save it\n",
    "    print(\"[INFO] Saving...\")\n",
    "    joblib.dump(model,path_save_model)\n",
    "    # return it\n",
    "    print(\"[INFO] Done.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to perform normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def normality_test(dataset):\n",
    "    '''\n",
    "    Performs three normality tests on the data:\n",
    "    Shapiro-Wilker and D'Agostino.\n",
    "    '''\n",
    "    shapiro = [p for (_,p) in map(stats.shapiro, [dataset[c] for c in dataset.columns])]\n",
    "    _, dagostino = stats.normaltest(dataset)\n",
    "    return {'shapiro':shapiro, 'dagostino':dagostino}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset shape:  (14421, 54)\n",
      "[INFO] Dataset shape:  (4808, 54)\n",
      "[INFO] Dataset shape:  (14421, 6)\n",
      "[INFO] Dataset shape:  (4808, 6)\n"
     ]
    }
   ],
   "source": [
    "original_train_dataset, original_train_targets = load_dataset(['../datasets/covertype_norm_train.csv'])\n",
    "original_test_dataset, original_test_targets = load_dataset(['../datasets/covertype_norm_test.csv'])\n",
    "lda_train_dataset, lda_train_targets = load_dataset(['../datasets/covertype_lda_train.csv'])\n",
    "lda_test_dataset, lda_test_targets = load_dataset(['../datasets/covertype_lda_test.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorgreati/miniconda3/envs/ia/lib/python3.7/site-packages/scipy/stats/morestats.py:1309: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n",
      "/home/vitorgreati/miniconda3/envs/ia/lib/python3.7/site-packages/scipy/stats/morestats.py:1306: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normality tests for original: \n",
      " {'shapiro': [0.0, 0.0, 2.802596928649634e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 5.083340120300435e-30, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'dagostino': array([0.00000000e+000, 0.00000000e+000, 2.76074249e-136, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       1.62863745e-061, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       5.09771520e-061, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       6.06404803e-001, 6.06404803e-001, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       6.06404803e-001, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
      "       0.00000000e+000, 0.00000000e+000])}\n",
      "[INFO] Normality tests for LDA: \n",
      " {'shapiro': [0.0, 0.0, 3.835278953208948e-32, 1.1201098507078527e-38, 0.0, 0.0], 'dagostino': array([0.00000000e+00, 0.00000000e+00, 7.16313520e-01, 9.96070832e-88,\n",
      "       0.00000000e+00, 0.00000000e+00])}\n"
     ]
    }
   ],
   "source": [
    "normality_original = normality_test(original_train_dataset)\n",
    "normality_lda = normality_test(lda_train_dataset)\n",
    "print(\"[INFO] Normality tests for original: \\n\", normality_original)\n",
    "print(\"[INFO] Normality tests for LDA: \\n\", normality_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fitting...\n",
      "[INFO] Saving...\n",
      "[INFO] Done.\n",
      "[INFO] Fitting...\n",
      "[INFO] Saving...\n",
      "[INFO] Done.\n"
     ]
    }
   ],
   "source": [
    "# train with original\n",
    "original_model = prepare_naive_model(original_train_dataset, original_train_targets, '../models/naive_original.save')\n",
    "# train with original\n",
    "lda_model = prepare_naive_model(lda_train_dataset, lda_train_targets, '../models/naive_lda.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "We're going to use the accuracy score with respect to the test set in order to evaluate the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Original acc score: 0.4317803660565724\n",
      "[INFO] Confusion matrix: \n",
      "[[  9   9   4   0 104  38 522]\n",
      " [  0  68  64  11 198  62 284]\n",
      " [  0   0 246 438   1   2   0]\n",
      " [  0   0   0 687   0   0   0]\n",
      " [  0   1 159   0 322 134  71]\n",
      " [  0   0 215 389  15  68   0]\n",
      " [  0   0   2   0   9   0 676]]\n",
      "[INFO] Precision, recall, fscore, support \n",
      "(0.5477038695404968, 0.4316933082831208, 0.343567904249623, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "original_preds = original_model.predict(original_test_dataset)\n",
    "original_acc_score = accuracy_score(original_test_targets, original_preds)\n",
    "print(\"[INFO] Original acc score:\", original_acc_score)\n",
    "print(\"[INFO] Confusion matrix: \")\n",
    "print(confusion_matrix(original_test_targets, original_preds))\n",
    "print(\"[INFO] Precision, recall, fscore, support \")\n",
    "print(precision_recall_fscore_support(original_test_targets, original_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] LDA acc score: 0.6356073211314476\n",
      "[INFO] Confusion matrix: \n",
      "[[483  98   1   0  28   2  74]\n",
      " [210 288  20   0 132  29   8]\n",
      " [  0   1 319  86  23 258   0]\n",
      " [  0   0  63 566   0  58   0]\n",
      " [ 33 134  62   0 436  22   0]\n",
      " [  0  16 169  28  65 409   0]\n",
      " [129   1   2   0   0   0 555]]\n",
      "[INFO] Precision, recall, fscore, support \n",
      "(0.6383655658669276, 0.6356215599152948, 0.6343086072006612, None)\n"
     ]
    }
   ],
   "source": [
    "lda_preds = lda_model.predict(lda_test_dataset)\n",
    "lda_acc_score = accuracy_score(lda_test_targets, lda_preds)\n",
    "print(\"[INFO] LDA acc score:\", lda_acc_score)\n",
    "print(\"[INFO] Confusion matrix: \")\n",
    "print(confusion_matrix(lda_test_targets, lda_preds))\n",
    "print(\"[INFO] Precision, recall, fscore, support \")\n",
    "print(precision_recall_fscore_support(lda_test_targets, lda_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset shape:  (19229, 54)\n",
      "elevation           0.063029\n",
      "aspect              0.026981\n",
      "slope              -0.024508\n",
      "horiz_dist_hydro    0.054084\n",
      "vert_dist_hydro     0.033909\n",
      "horiz_dist_road     0.051260\n",
      "hillshade_9        -0.006286\n",
      "hill_shade_noon     0.043517\n",
      "hill_shade_15       0.031287\n",
      "horiz_dist_fire     0.046283\n",
      "wild_area_0         0.016658\n",
      "wild_area_1         0.022170\n",
      "wild_area_2         0.021860\n",
      "wild_area_3        -0.047225\n",
      "soil_type_0        -0.007470\n",
      "soil_type_1        -0.006244\n",
      "soil_type_2        -0.018280\n",
      "soil_type_3        -0.006882\n",
      "soil_type_4         0.001309\n",
      "soil_type_5        -0.007912\n",
      "soil_type_6              NaN\n",
      "soil_type_7              NaN\n",
      "soil_type_8         0.014967\n",
      "soil_type_9        -0.040811\n",
      "soil_type_10       -0.001757\n",
      "soil_type_11        0.012847\n",
      "soil_type_12        0.005309\n",
      "soil_type_13       -0.001807\n",
      "soil_type_14             NaN\n",
      "soil_type_15        0.007805\n",
      "soil_type_16       -0.013800\n",
      "soil_type_17        0.013857\n",
      "soil_type_18        0.015126\n",
      "soil_type_19        0.009147\n",
      "soil_type_20        0.016909\n",
      "soil_type_21        0.011070\n",
      "soil_type_22        0.002616\n",
      "soil_type_23        0.011232\n",
      "soil_type_24        0.020118\n",
      "soil_type_25        0.016303\n",
      "soil_type_26        0.021097\n",
      "soil_type_27        0.018911\n",
      "soil_type_28        0.000019\n",
      "soil_type_29       -0.005615\n",
      "soil_type_30        0.007818\n",
      "soil_type_31        0.006415\n",
      "soil_type_32        0.007360\n",
      "soil_type_33        0.019111\n",
      "soil_type_34        0.014968\n",
      "soil_type_35        0.020425\n",
      "soil_type_36        0.016050\n",
      "soil_type_37        0.014062\n",
      "soil_type_38        0.009673\n",
      "soil_type_39        0.023878\n",
      "dtype: float64\n",
      "[INFO] Dataset shape:  (19229, 6)\n",
      "0    0.168511\n",
      "1    0.166823\n",
      "2    0.168681\n",
      "3    0.162201\n",
      "4    0.167104\n",
      "5    0.167828\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original_dataset, original_targets = load_dataset(['../datasets/covertype_norm_train.csv','../datasets/covertype_norm_test.csv'])\n",
    "print(original_dataset.corr().mean())\n",
    "\n",
    "lda_dataset, lda_targets = load_dataset(['../datasets/covertype_lda_train.csv','../datasets/covertype_lda_test.csv'])\n",
    "print(lda_dataset.corr().mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
